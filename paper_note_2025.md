# Evidence of a social evaluation penalty for using AI

## 一、研究目标、实际问题及产业意义
### （一）研究目标
论文旨在探究人们使用人工智能（AI）工具时所面临的社会评价问题，验证人们是否会因使用AI而被他人负面评价，以及这种负面评价是否存在合理性。

### （二）实际问题
随着AI工具在工作场所的快速普及，尽管其能提升生产力，但人们对使用AI存在顾虑，如担心被视为懒惰、能力不足等，且有报告显示人们会主动隐瞒AI使用情况。论文试图解决“使用AI是否会导致社会评价降低”这一关键问题。

### （三）产业意义
- 揭示AI adoption的潜在障碍：社会评价带来的惩罚可能阻碍员工采用AI工具，影响组织生产力提升。
- 为组织管理提供参考：帮助企业制定政策，缓解员工对使用AI的担忧，促进AI在工作中的合理应用。
- 推动AI伦理与社会接受度研究：有助于开发更符合人类社会认知的AI技术，提升其社会适应性。

## 二、新的思路、方法或模型
### （一）新的思路
- **将归因理论应用于AI使用场景**：传统归因理论认为观察者倾向于将他人行为归因于内在特质而非外部情境。论文延伸此理论，提出人们使用AI时，他人更可能将其行为归因于能力或动机不足，而非AI工具的辅助作用。
- **关注AI使用的社会动态**：以往研究多聚焦于人们对AI系统本身的感知，而本研究关注使用AI的人所受到的社会评价，填补了这一研究空白。

### （二）方法特点与优势
- **多实验设计**：通过四个 pre-registered 实验，从不同角度验证假设，包括预期评价、实际评价、 hiring 决策及中介效应等，增强了研究的可靠性和说服力。
- **对比不同帮助来源**：在实验中设置AI帮助、非AI帮助和无帮助条件，明确AI使用与其他帮助形式在社会评价上的差异。
- **量化社会评价维度**：使用多个维度（如 laziness、competence、diligence 等）量化社会评价，使研究结果更具可测性和可比性。

## 三、实验验证
### （一）实验设计与数据结果
#### 1. 研究1：预期社会评价
- **设计**：招募500名在线参与者，随机分为AI工具组和非AI工具组，让其想象使用相应工具后，评价向经理和同事披露的可能性及预期被评价的维度。
- **结果**：
    - AI工具组认为自己会被视为更懒惰（M=3.25 vs 2.72）、更易被替代（M=3.39 vs 2.83），更不称职（M=4.72 vs 5.45）、更不勤奋（M=4.66 vs 5.25）。
    - AI工具组更不愿向经理（M=4.91 vs 5.25）和同事（M=4.85 vs 5.17）披露使用情况。

#### 2. 研究2：实际社会评价
- **设计**：1215名参与者阅读不同职业、年龄、性别的员工使用AI帮助、非AI帮助或无帮助的描述，评价其懒惰程度和代理维度。
- **结果**：
    - 使用AI帮助的员工被评为更懒惰（M=2.50 vs 2.16 vs 2.02），更不称职、不勤奋、不独立、不自信。
    - 目标的年龄、性别、职业不影响AI使用对懒惰等感知的影响。

#### 3. 研究3： hiring 决策
- **设计**：801名“候选人”完成任务后报告AI使用频率，1718名“经理”在 hiring 任务中评价使用AI或不使用AI的候选人。
- **结果**：
    - 经理自身AI使用频率影响对候选人的评价：不常使用AI的经理更倾向于认为使用AI的候选人任务契合度低，而常使用AI的经理则相反。
    - 在 hiring 决策中，不常使用AI的经理更倾向于 hire 不使用AI的候选人，常使用AI的经理则更倾向于 hire 使用AI的候选人。

#### 4. 研究4：中介效应与任务依赖性
- **设计**：1006名参与者想象 hiring  gig worker，候选人使用AI或传统工具，任务为手动或数字任务，评价懒惰感知和任务契合度。
- **结果**：
    - 使用AI的候选人被视为更懒惰，且这种懒惰感知中介了AI使用与任务契合度的关系。
    - 任务类型调节该关系：在数字任务中，AI使用的负面评价被抵消，甚至提升任务契合度（M=5.75 vs 5.58），而在手动任务中则相反（M=4.18 vs 4.75）。

## 四、未来研究方向与挑战
### （一）值得探索的问题
- **真实组织环境中的验证**：目前实验使用在线便利样本，未来需在实际组织中考察AI使用的社会评价对任务分配、绩效评估等的影响。
- **不同AI类型的影响**：论文中AI工具定义较宽泛，未来需研究不同类型AI（如辅助型、自动化型）对社会评价的影响差异。
- **长期效应研究**：随着AI使用的普及，社会评价是否会发生变化，如 stigma 减弱等。

### （二）技术与投资机会
- **AI透明度设计**：开发能清晰展示AI辅助过程的技术，减少他人对使用者能力的质疑。
- **组织培训项目**：针对员工和管理者开展培训，提升对AI的正确认知，缓解社会评价 penalty。
- **AI伦理与社会接受度研究工具**：开发评估AI使用社会影响的工具，为企业和政策制定提供依据。

## 五、研究不足与存疑
### （一）不足
- **样本局限性**：所有实验均使用在线便利样本，可能无法完全代表真实职场中的各类人群。
- **AI工具操作化局限**：AI工具描述较为一般，未充分捕捉现实中不同AI系统的特点及使用场景。
- **时间背景影响**：研究开展于2024-2025年，AI发展迅速，社会对AI的认知可能已发生变化，需后续研究验证结果的持续性。

### （二）存疑
- **因果关系的进一步明确**：虽然实验设计旨在验证因果关系，但现实中可能存在其他混淆因素影响社会评价。
- **文化差异影响**：研究未考察不同文化背景下对AI使用社会评价的差异，这可能是一个重要的调节因素。

## 六、创新想法与启发
### （一）重点学习内容
- **归因理论的创新应用**：将归因理论与AI使用结合，为理解AI adoption 障碍提供了新视角。
- **多维度社会评价的量化方法**：使用多个代理维度和严谨的实验设计，为类似研究提供了方法参考。
- **任务依赖性与AI使用的交互作用**：发现任务类型对AI使用社会评价的调节作用，为实际应用中选择AI使用场景提供了依据。

### （二）启发
- 在组织中推广AI时，需考虑员工对社会评价的担忧，通过沟通和培训缓解这种顾虑。
- 设计AI工具时，可考虑增加透明度，展示使用者的角色和AI的辅助作用，减少他人的负面归因。
- 在 hiring 等决策中，需意识到评价者自身AI使用经验可能影响对候选人的判断，避免偏见。

### （三）背景知识补充
- **归因理论（Attribution Theory）**：如 Heider 的人际关系心理学、Jones 和 Davis 的归因过程等。
- **印象管理（Impression Management）**：Goffman 的日常生活中的自我呈现理论。
- **AI与社会认知的相关研究**：如人们对AI代理性的感知及其对人际评价的影响。

****

# Computational analysis of 100 K choice dilemmas: Decision attributes, trade-­off structures, and model-­based prediction

## 1. 论文的研究目标、解决的实际问题及对产业发展的意义
- **研究目标**：运用大规模语言模型（LLM）分析超10万条真实生活选择困境，提取决策属性、解析权衡结构，并结合决策模型预测人类选择行为。
- **解决的实际问题**：传统决策科学研究多依赖实验室中高度简化的人工刺激（如仅涉及两三个属性的金钱赌博），难以捕捉现实生活中复杂决策的多维度考量（如职业、家庭、道德等因素），导致对真实决策行为的预测和干预效果有限。例如，实验室中的风险选择任务与现实风险行为相关性弱（如论文提到赌博选择任务与常见风险行为的相关性弱），时间偏好范式与实际健康、财务行为关联度低。
- **对产业发展的意义**：
    - 为行为科学研究提供新范式，推动决策理论在真实场景中的应用，如优化消费决策、健康管理等领域的干预策略。
    - 助力AI领域开发更贴近人类思维的决策模型，可应用于推荐系统、智能助手等，提升其决策建议的合理性。
    - 为市场调研、用户行为分析提供量化工具，企业可通过分析用户生成的文本数据（如社交媒体评论），挖掘消费者决策背后的关键属性，优化产品设计与营销策略。

## 2. 具体研究内容

### 研究1：美国代表性样本的选择困境收集
- **目的**：验证社交媒体数据（Reddit）与线下调查数据的决策属性一致性，确保研究结论的普适性。
- **方法**：
    - 通过Prolific Academic招募497名美国参与者（48%男性，平均年龄48岁），要求每人描述3个亲身经历的二元选择困境。
    - 每个困境需包含选项描述、权衡因素及优先目标，文本长度至少250字符，避免使用生成式AI。
- **关键结果**：
    - 共收集1,491个选择困境，经LLM处理后与r/Advice子版块数据的属性频率高度相关（r=0.90，P<0.001）。
    - 证明社交媒体数据能有效反映现实决策结构，如职业、家庭等属性的分布与调查数据一致。

### 研究2：LLM生成内容的准确性验证
- **目的**：检验GPT对选择选项及成本/收益描述的准确性。
- **方法**：
    - 从r/Advice随机选取100个困境，让49名参与者（63%男性，平均年龄27岁）判断GPT生成的困境分析（可能面临的选项及成本/收益描述）是否准确。
    - 采用二元评分（准确/不准确），计算模态判断（多数人共识）。
- **关键数据**：
    - 选项描述准确率达95.51%，成本/收益原因的平均准确率为90.29%。
    - 首次生成的原因准确率最高（>85%），后续生成的原因准确率略有下降但仍显著高于随机水平。

### 研究3：属性编码的语义一致性验证
- **目的**：验证SBERT句子嵌入模型将自然语言原因映射到理论属性的准确性。
- **方法**：
    - 对207个决策属性，各选取20个与属性高/低相似度的GPT生成原因（基于余弦相似度），组成621对测试样本。
    - 100名参与者（63%男性，平均年龄34岁）需判断每对中哪条原因更符合目标属性。
- **关键结果**：
    - 属性编码准确率高达98.53%，即模型能准确识别与属性语义相关的原因。
    - 证明LLM提取的属性与行为科学理论定义的维度高度一致。

### 研究4a和4b：选择预测的模型有效性验证
- **目的**：检验LLM属性结合决策模型对选择行为的预测能力。
- **方法**：
    - **Study 4a**：选取8个涉及“家庭亲密与安全”vs“实用与财务谨慎”权衡的困境，300名参与者（51%男性，平均年龄31岁）进行7点李克特评分。
    - **Study 4b**：针对“婚姻满足”vs“金钱财务”的权衡困境，300名新参与者重复实验。
    - 对比模型：个体加权加性模型（基于LLM属性）、非结构化文本模型、随机属性模型、人口统计学模型。
- **关键数据**：
    - Study 4a中，LLM模型的平均R²=0.24，显著优于文本模型（R²=0.14）和随机模型（R²≈0）。
    - Study 4b得到相似结果（R²=0.14和0.17），且跨参与者预测中，基于属性 congruence 的模型性能远超人口统计学模型（R²<0.02）。

### 研究5a和5b：决策思维过程的文本分析
- **目的**：验证LLM能否捕捉决策时的言语化推理过程。
- **方法**：
    - **Study 5a**：302名参与者对Study 4a中最接近50%选择率的困境列出思考过程，并对每条想法标注为某选项的成本/收益。
    - **Study 5b**：针对Study 4b的困境重复实验，302名新参与者参与。
    - 分析方法：比较参与者自我编码的想法方向（收益-成本差）与LLM编码的相关性，以及对选择偏好的预测力。
- **关键发现**：
    - 参与者自我编码的想法方向与偏好的R²=0.42（Study 5a）和0.32（Study 5b）。
    - LLM对想法的编码与参与者自我编码的相关性r=0.66和0.47，且基于LLM编码的预测模型（R²=0.34和0.17）优于人口统计学和人格模型。
    - 证明LLM能有效捕捉决策中的显性推理逻辑。

### 3. 论文的不足及缺失
- **数据局限性**：
    - 社交媒体数据可能存在自我呈现偏差，用户可能为获得认同而美化决策描述。尽管论文提到r/Advice版规限制寻求确认的帖子，但仍难以完全避免。
    - 样本主要来自英语使用者和美国人口，可能无法完全反映多元文化下的决策模式。
- **模型局限性**：
    - 加权加性模型假设属性可线性组合，可能无法捕捉某些决策中的非线性权衡（如风险厌恶的非线性特征）。
    - LLM生成的属性可能受训练数据影响，存在潜在的偏见或遗漏重要属性。
- **理论验证的不足**：
    - 虽然模型在预测选择上表现优于对比模型，但对决策过程的理论解释（如属性权重的心理机制）仍需更深入的验证。
    - 实验中使用的困境多为高 stakes决策，对日常琐碎决策的适用性尚未检验。

### 4. 可借鉴的创新想法、启发及需补充的背景知识
- **可重点学习的创新想法**：
    - **跨学科研究范式**：将自然语言处理与认知决策理论结合，利用大规模文本数据挖掘真实决策结构，为行为科学研究提供新路径。
    - **自动化属性编码框架**：LLM+句子嵌入的组合方法可高效提取决策属性，适用于大规模数据的快速分析，具有很强的可复制性。
    - **决策预测的多模型融合**：将结构化属性与传统决策模型结合，优于单一依赖文本或人口统计特征的模型，体现了融合方法的优势。
- **启发**：
    - 在研究复杂人类行为时，结合自然istic数据与计算模型可能比传统实验室方法更有效。
    - 文本数据中蕴含丰富的决策信息，通过AI技术可将其转化为结构化知识，用于指导现实决策。
- **需补充的背景知识**：
    - **决策理论基础**：如加权加性规则、多属性效用理论等，理解传统决策模型的假设与应用场景。
    - **自然语言处理技术**：包括LLM的工作原理、句子嵌入模型（如SBERT）的构建与应用，以便更好地理解属性提取过程。
    - **认知心理学中的决策研究**：了解经典决策偏差（如框架效应、损失厌恶）、属性权衡机制等，为解读实验结果提供理论支撑。
****

# Bridging the human–AI knowledge gap through concept discovery and transfer in AlphaZero

## 一、研究目标与实际问题
### 1.1 研究目标
论文旨在从具有高性能的AI系统AlphaZero中提取隐藏的知识，并将其从AI中迁移出来，以指导人类，拓展人类的知识边界。具体而言，研究团队希望开发一种方法，能够从AlphaZero的内部表征中发现新的国际象棋概念，并验证这些概念是否可教给人类专家，从而弥合人类与AI之间的知识鸿沟（$M-H$）。

### 1.2 实际问题
- **AI知识提取难题**：AI系统内部知识难以提取，其可能的内部表征空间庞大，寻找有意义的新概念犹如“大海捞针”。
- **人类与AI知识鸿沟**：AI系统（如AlphaZero）具备超人类能力，但人类对其独特知识（$M-H$）的理解有限。例如，AlphaGo在与李世石的比赛中第37步的“神之一手”，便是AI独特知识的体现。
- **传统方法的局限性**：现有研究多关注人类与AI的共同知识（$M\cap H$），如可解释性研究试图将AI知识强行纳入人类理解框架，但效果有限。

## 二、新的思路、方法与模型
### 2.1 概念发现框架
研究团队提出了一个端到端的概念发现框架，用于从AlphaZero中提取新的国际象棋概念，具体步骤如下：
- **概念向量挖掘**：利用凸优化从AlphaZero的潜在空间中挖掘代表概念的向量。通过最小化$L_1$范数来鼓励稀疏性，公式为：
```math
min \left\| v_{c, l}\right\| _{1}
```
以满足概念约束条件。其中，$v_{c, l}$为层$l$中表示概念$c$的向量。

- **动态概念约束**：通过对比AlphaZero的蒙特卡洛树搜索（MCTS）中的最优rollout（$\mathbb{X}_{≤T}^{+}$）和次优rollout（$\mathbb{X}_{≤T}^{-}$）来设置概念约束。对于动态概念，要求最优rollout的激活内积高于次优rollout，公式为：
```math
v_{c, l}^{\top} z_{t, l}^{+} \geq v_{c, l}^{\top} z_{t, l}^{-}, for~all~t \leq T
```

- **概念过滤**：
    - **可教性**：通过将概念原型教给另一个AI代理，评估其性能提升。若代理在学习后能更好地解决相关任务，则概念具有可教性。
    - **新颖性**：利用谱分析，通过计算概念向量在AlphaZero游戏和人类游戏向量空间中的重建损失差异来衡量新颖性。新颖性分数定义为：
```math
min _{\beta_{l}}\left\| v_{c, l}-\sum_{i=1}^{k} \beta_{i, l} u_{i, l}^{h}\right\| ^{2}-min _{\gamma_{l}}\left\| v_{c, l}-\sum_{i=1}^{k} \gamma_{i, l} u_{i, l}^{a}\right\| ^{2}
```
其中，$u_{i, l}^{h}$和$u_{i, l}^{a}$分别为人类和AlphaZero游戏向量空间的基向量。

### 2.2 与传统方法的对比
- **无监督发现**：无需人类标签，通过MCTS统计自动发现动态概念，而传统方法多依赖监督学习或人类先验知识。
- **关注动态概念**：不仅考虑单个状态的静态概念，还关注序列状态中的动态概念，更符合国际象棋的决策特点。
- **双重过滤机制**：通过可教性和新颖性双重过滤，确保发现的概念有用且新颖，而传统方法可能缺乏对概念实用性的系统评估。

## 三、实验验证
### 3.1 实验设计
- **AI代理实验**：
    - **学生网络**：学生网络是一个深度学习模型。选择AlphaZero训练过程中的一个检查点，其与教师网络的策略重叠率小于0.2。
    - **教学过程**：使用概念原型训练学生网络，对比其在测试集上的性能与使用随机数据训练的结果。
- **人类实验**：
    - **参与者**：四位顶尖国际象棋特级大师（包括前世界冠军和现任世界冠军）。
    - **实验阶段**：
        1. **基线阶段**：解决与概念对应的谜题。
        2. **学习阶段**：观察AlphaZero移动棋子的最优决策序列。
        3. **测试阶段**：解决未见过的同概念谜题。

### 3.2 实验结果
- **AI代理实验**：
    - 当使用概念原型训练时，学生网络在概念测试集上的性能显著提升。例如，在50个训练周期后，学生网络的性能相当于使用自我对弈训练1万至25万次的结果。
    - 与使用随机数据训练相比，使用概念原型训练的学生网络在概念测试集上的正确移动选择率更高（如深绿色线高于浅绿色线）。
- **人类实验**：
    - 所有特级大师在测试阶段的表现均优于基线阶段。例如，特级大师1从基线阶段的0/12正确提升至测试阶段的5/12正确，提升了42%。
    - 平均而言，特级大师在概念层面的表现提高了0.85个正确谜题，标准误差为0.12，具有统计学意义。

## 四、未来研究方向（认知心理学视角）
### 4.1 可探索的问题
- **人类概念学习机制**：深入研究人类专家如何从AI概念原型中学习，探索其认知过程与传统学习方式的差异。
- **概念表征差异**：进一步分析人类与AI在概念表征上的差异，如AlphaZero对材料价值的重视程度较低，更灵活地在棋盘两侧切换，这对理解人类认知偏见有启示。
- **最佳教学条件**：探索人类学习AI新概念的最佳条件，如时间投入、互动方式等。例如，是否允许无限时间学习或增加互动环节能提高学习效果。

### 4.2 面临的挑战
- **概念语言鸿沟**：AI概念可能需要新的语言来描述，如何建立人类与AI之间的共同语言是一个挑战。
- **个体差异**：不同人类学习者的认知能力和背景不同，如何根据个体调整教学方法。
- **复杂概念整合**：一个计划可能包含多个概念，如何帮助人类理解和整合这些复杂概念。

## 五、批判视角下的不足
### 5.1 方法局限性
- **线性假设**：假设概念在潜在空间中是线性表示的，可能忽略非线性概念。
- **概念复杂性**：对于复杂概念，可能无法完全通过线性向量和凸优化来捕捉其本质。

### 5.2 实验局限性
- **样本量小**：人类实验仅涉及四位特级大师，结果可能不具有广泛代表性。
- **时间限制**：特级大师的学习时间有限，可能未充分掌握概念。
- **混淆因素**：性能提升可能部分归因于引导参与者寻找更复杂的模式，而非对特定概念的理解。

### 5.3 未解决的问题
- **概念可解释性**：虽然发现了概念，但对其具体含义的解释仍有限，需要进一步的图分析等方法来理解。
- **跨领域应用**：该方法在国际象棋中的成功是否可推广到其他领域（如科学、医学）尚需验证。

## 六、创新想法与启发
### 6.1 重点学习内容
- **无监督概念发现方法**：利用凸优化和MCTS统计从AI内部表征中发现新概念的框架。
- **可教性和新颖性评估指标**：设计合理的指标来评估概念的实用性和新颖性。
- **概念原型教学法**：通过谜题原型向人类传授AI概念的方法。

### 6.2 启发
- **AI作为知识源**：AI系统可作为发现新知识的来源，拓展人类认知边界。
- **跨学科研究**：结合机器学习和认知心理学，探索人类与AI的知识交互方式。
- **方法通用性**：该框架可能为其他领域的AI知识提取提供借鉴。

### 6.3 背景知识补充
- **强化学习基础**：了解AlphaZero的工作原理，如策略价值网络和蒙特卡洛树搜索。
- **概念学习理论**：认知心理学中关于人类概念学习的理论，如维果茨基的最近发展区理论。
- **可解释AI技术**：如概念激活向量（TCAV）等方法，以更好地理解AI内部表征。
*******

# Large language models that replace human participants can harmfully misportray and flatten identity groups
### 1. 论文的研究目标与实际问题解决
#### 1.1 研究目标
论文旨在揭示大型语言模型（LLMs）在替代人类参与者时，对社会身份群体的表征存在根本性缺陷，并通过理论分析与实证研究验证这些缺陷的危害。

#### 1.2 实际问题
- **代表性采样难题**：在计算社会科学、用户测试等领域，研究者需招募具有人口学代表性的参与者，而LLMs若要替代人类，需捕捉性别、种族等社会身份的影响。
- **身份表征失真**：现有LLMs训练机制导致其对 demographic groups 的表征存在“误刻画”（misportrayal）与“扁平化”（flattening）问题，如将女性群体的观点简化为单一叙事。
- **边缘化群体风险**：这些失真对边缘化群体（如非二元性别者、残障人士）尤为有害，可能延续历史上的认知不公（epistemic injustice）。
- **misportrayal**: “误刻画”（misportrayal）指的是大型语言模型（LLMs）在被提示特定社会身份时，其生成的响应更倾向于反映外群体（out-group）对该身份的刻板印象或片面认知，而非内群体（in-group）成员的真实自我表达。
- **flattening**: “flatten”（扁平化）指的是大型语言模型（LLMs）在表征人口统计群体（demographic groups）时，无法捕捉群体内部的多元性和异质性，将复杂的身份特征简化为单一、同质化的表达。
- **Essentializing identity**：“Essentializing identity”（身份本质化）是指在使用大型语言模型（LLMs）时，通过身份提示将社会身份固化为一种固定、不可改变的核心特征，忽略身份的复杂性和动态性，进而强化 “不同群体间的差异是天生且不可逾越” 的认知偏差。

| Problem | Inherent limitation | Measurements | Reason for harm | Prompting alternative |
| --- | --- | --- | --- | --- |
| Misportraying more like out- group imitations rather than in- group representations | Given the written text that LLMs are trained on, an author’s demographic identities are rarely associated with the text itself. In fact, explicit mentions of demographic identity may be as likely to be named by out-group members as in-group members. | (1) Ngram: average pairwise Jaccard distance (2) Ngram: closest-point Jaccard distance (3) SBERT: average pairwise cosine distance (4) SBERT: closest-point cosine distance (5) MC: Wasserstein distance (6) MC: mean diference | Speaking for others can involve the erasure of marginalized voices and reinscription of social hierarchies. | Identity-coded names (for example., Darnell Pierre) instead of identity (for example, Black man) |
| Flattening demographic groups | Because of loss functions like cross- entropy used during training, models are rewarded for producing the more likely output for any given piece of text, disincentivizing a wide range of permissible answers for any given question. | (1) Ngram: proportion unique (2) SBERT: average pairwise cosine distance (3) SBERT: trace of covariance matrix (4) MC: number of unique responses | Marginalized groups are historically portrayed one dimensionally, and the failure to recognize in-group diferences can preclude intersectionality. | Increasing temperature hyperparameter or other prompt-based techniques to increase diversity |
| Essentializing identity | Prompting with identities inherently essentializes identity as a relevant diference factor. | (1) SBERT: determinant of covariance matrix (2) SBERT: Vendi score (3) MC: number of unique responses | Essentializing identity can reinforce demographic diferences as inherent and insurmountable. | Prompt along other axes like behavioural persona or political orientation |


### 2. 新思路、方法与模型特点。

#### 2.1 创新方法
- **多维度测量体系**：结合N-gram Jaccard距离、SBERT余弦距离、Wasserstein距离等6种指标，量化LLM响应与人类内/外群体响应的差异。
- **身份提示实验设计**：针对16种 demographic identities（如黑人女性、Z世代），设计四类问题（R1-R4），比较LLMs（Llama2、GPT-4等）与3200名人类参与者的回答。

#### 2.2 与前人研究的差异
- **聚焦自由响应而非多选**：突破传统LLM研究的多选范式，通过开放式回答揭示身份表征的细微偏差。
- **个体层面分析**：关注群体内差异而非总体平均，例如发现LLMs对“非二元性别者”的回答忽视其代词使用的多样性。

### 3. 实验设计与关键结果
#### 3.1 实验设计
- **参与者与模型**：招募美国Prolific平台参与者，覆盖5大维度（种族、性别、年龄等）；测试4种LLMs（含开源与闭源）。
- **问题类型**：
  - R1-Contingent：如“作为美国女性的生活体验”
  - R2-Relevant：如“对移民政策的看法”
  - R3-Subjective：如“判断文本毒性”
  - R4-Coverage：如“技术在治疗中的角色”
- **对比组**：人类内群体响应 vs. 人类外群体模仿 vs. LLM响应

#### 3.2 关键数据与结果
- **误刻画证据**：
  - GPT-4在R1/R2问题上，67%的非二元性别者响应更接近外群体模仿（图2）。
  - 视障者身份的LLM响应中，83%的SBERT距离指标显示与外群体更相似。
- **扁平化证据**：
  - 所有LLMs的响应多样性（如唯一N-gram比例）比人类低40%-60%（图4）。
  - GPT-4在“非二元性别体验”问题上，90%回答仅聚焦代词忽视问题，而人类参与者提及身份认同的复杂性。
- **缓解策略效果**：
  - 使用身份编码姓名（如Darnell Pierre）替代标签，使黑人女性响应的内群体相似度提升25%（图3）。
  - 提高温度参数至1.4时，LLM响应多样性接近人类，但伴随语义不连贯。

#### 3.3 启示
- 相对于直接使用身份标签（如“黑人女性”、“z世代”），使用相关身份具有的特征作为提示可以增加LLM回复的覆盖度
- 为了增加回复多样性，可以适当增加温度参数

### 4. 未来研究方向与挑战（认知心理学视角）
#### 4.1 理论拓展
- **具身认知（Embodied Cognition）缺失**：LLMs缺乏身体经验（如残障者的感知方式），未来需探索具身化训练数据的整合。
- **社会认知理论应用**：借鉴刻板印象内容模型（SCM），分析LLMs如何习得群体间的情感与认知偏差。

#### 4.2 方法创新
- **神经认知指标融合**：结合眼动追踪、fMRI等技术，比较人类与LLM在处理身份相关信息时的认知模式差异。
- **动态身份建模**：开发能捕捉身份流动性（如跨情境的性别表达）的LLM架构，而非静态标签提示。

#### 4.3 伦理挑战
- **认知不公的算法延续**：需建立“身份表征伦理审查框架”，避免LLMs强化历史上对边缘化群体的认知剥夺。
- **替代边界界定**：明确LLMs可补充（如试点研究）但不可替代人类的场景，如涉及创伤经历的调研。

### 5. 研究不足与存疑之处
#### 5.1 方法局限
- **训练数据覆盖不足**：实验仅针对美国16个群体，未涉及全球37%未联网人口及口头文化群体。
- **提示工程优化空间**：身份编码姓名的效果在白人群体中不显著（图3），需探索更普适的提示策略。

#### 5.2 理论缺口
- **身份交互效应缺失**：未分析多重身份（如黑人女性+残障）的交叉影响，而交叉性理论（Intersectionality）指出单一维度分析存在局限。
- **动态语境处理不足**：LLMs在不同社会情境（如家庭vs.职场）中的身份表征差异未被考察。

#### 5.3 实证存疑
- **人类数据代表性问题**：Prolific参与者可能存在技术偏好偏差，需与全国代表性样本对比。
- **长期影响未验证**：LLMs持续替代人类是否会加剧社会认知同质化，缺乏纵向研究证据。

### 6. 创新想法与启发
#### 6.1 可复用创新点
- **身份提示替代策略**：使用行为 persona（如“喜欢徒步的环保主义者”）而非 demographic标签，提升响应多样性（图6显示随机persona的覆盖度更高）。
- **多指标交叉验证**：在LLM评估中结合N-gram、SBERT、Wasserstein距离等多维度指标，避免单一方法偏差。

#### 6.2 启发与背景知识补充
- **必学理论**：
  - 立场理论（Standpoint Theory）：理解社会位置如何塑造认知。
  - 认知不公理论：掌握证言不公（Testimonial Injustice）与解释不公（Hermeneutical Injustice）的机制。
- **技术工具**：
  - Sentence-BERT嵌入分析：用于量化文本语义相似度。
  - 交叉熵损失函数原理：理解LLM扁平化的技术根源。

#### 6.3 实践应用建议
- **在用户研究中**：仅将LLMs用于补充假设生成，而非替代真实用户访谈，尤其涉及敏感身份时。
- **在算法开发中**：将“身份表征多样性”作为模型评估指标，如计算响应的SBERT协方差矩阵迹（trace）。

> 论文结论强调：“We urge caution in replacements... but inference-time techniques like identity-coded names can reduce harms.” 这为实际应用提供了权衡框架。